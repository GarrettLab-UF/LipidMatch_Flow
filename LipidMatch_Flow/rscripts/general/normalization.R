##################################################
## R script for MetaboAnalyst
## Description: perform various normalization
##
## Author: Jeff Xia, jeff.xia@mcgill.ca
## McGill University, Canada
##
## License: GNU GPL (>= 2)
###################################################

# get the dropdown list for sample normalization view
GetPrenormSmplNms <-function(){
    if(is.null(dataSet$prenorm)){
        dataSet$prenorm <<- dataSet$proc;
    } 
    return(rownames(dataSet$prenorm));
}

GetPrenormFeatureNms <- function(){
    if(is.null(dataSet$prenorm)){
        dataSet$prenorm <<- dataSet$proc;
    }
    return(colnames(dataSet$prenorm));
}

GetPrenormClsNms <- function(){
    if(is.null(dataSet$prenorm.cls)){
        dataSet$prenorm.cls <<- dataSet$proc.cls;
        if(substring(dataSet$format,4,5)=="ts"){
            dataSet$prenorm.facA <<- dataSet$proc.facA;
            dataSet$prenorm.facB <<- dataSet$proc.facB;
        }
    }
    return(levels(dataSet$prenorm.cls));
}

###############################################################
# remove the sample or feature from data 
# Note: this should happen after processing and before normalization 
# dataSet$proc dataSet$proc.cls (make a copy of this pair for restore)
########################################################

UpdateGroupItems<-function(){
    if(!exists("grp.nm.vec")){
        current.msg <<- "Cannot find the current group names!";
        return (0);
    }

    hit.inx <- dataSet$proc.cls %in% grp.nm.vec;
    dataSet$prenorm <<- CleanDataMatrix(dataSet$proc[hit.inx,]);
    dataSet$prenorm.cls <<- factor(dataSet$proc.cls[hit.inx], levels=grp.nm.vec);

    if(substring(dataSet$format,4,5)=="ts"){
        dataSet$prenorm.facA <<- factor(dataSet$proc.facA[hit.inx],levels=grp.nm.vec);
        dataSet$prenorm.facB <<- factor(dataSet$proc.facB[hit.inx],levels=grp.nm.vec);
    }

    current.msg <<- "Successfully updated the group items!";
    return(length(levels(dataSet$prenorm.cls)));
}

CleanDataMatrix <- function(ndata){
    # make sure no costant columns crop up
    varCol <- apply(ndata, 2, var, na.rm=T);
    constCol <- (varCol == 0 | is.na(varCol));
    return(ndata[,!constCol]);
}

UpdateSampleItems<-function(){
    if(!exists("smpl.nm.vec")){
        current.msg <<- "Cannot find the current sample names!";
        return (0);
    }

    hit.inx <- rownames(dataSet$proc) %in% smpl.nm.vec;
    dataSet$prenorm <<- CleanDataMatrix(dataSet$proc[hit.inx,]);
    dataSet$prenorm.cls <<- dataSet$proc.cls[hit.inx];
    if(substring(dataSet$format,4,5)=="ts"){
        dataSet$prenorm.facA <<- dataSet$proc.facA[hit.inx];
        dataSet$prenorm.facB <<- dataSet$proc.facB[hit.inx];
    }
    current.msg <<- "Successfully updated the sample items!";
    return(length(levels(dataSet$prenorm.cls)));
}

UpdateFeatureItems<-function(){
    if(!exists("feature.nm.vec")){
        current.msg <<- "Cannot find the selected feature names!";
        return (0);
    }

    hit.inx <- colnames(dataSet$proc) %in% feature.nm.vec;
    dataSet$prenorm <<- CleanDataMatrix(dataSet$proc[,hit.inx]);
    dataSet$prenorm.cls <<- dataSet$proc.cls; # this is the same
    current.msg <<- "Successfully updated the sample items!";
    return (1);
}


Normalization<-function(rowNorm, transNorm, scaleNorm, ref=NULL, ratio=FALSE, ratioNum=20){

    # now do actual filter if indicated
    if(!is.null(dataSet$remain.nms)){
        hit.inx <- colnames(dataSet$prenorm) %in% dataSet$remain.nms;
        #if(rowNorm == "CompNorm"){
        #    # make sure the ref is there, not filtered out
        #    hit.inx <- match(ref, colnames(dataSet$prenorm));
        #    remain[hit.inx] <- TRUE;
        #}
        data <- dataSet$prenorm[, hit.inx];
    }else{
        data <- dataSet$prenorm;
    }

    if(is.null(dataSet$prenorm.cls)){ # can be so for regression 
        dataSet$prenorm.cls <<- dataSet$proc.cls;
        #dataSet$prenorm.cls <- dataSet$proc.cls;
    }

    cls <- dataSet$prenorm.cls;
    if(substring(dataSet$format,4,5)=="ts"){
        dataSet$facA <- dataSet$prenorm.facA;
        dataSet$facB <- dataSet$prenorm.facB;
        cls <- dataSet$facA;
    }
    
    # note, samples may not be sorted by group labels
    if(substring(dataSet$format,4,5)=="ts"){
        nfacA <- dataSet$facA;
        nfacB <- dataSet$facB;
        if(dataSet$design.type =="time" | dataSet$design.type =="time0"){
            # determine time factor and should order first by subject then by each time points
            if(tolower(dataSet$facA.lbl) == "time"){ 
                time.fac <- nfacA;
                exp.fac <- nfacB;
            }else{
                time.fac <- nfacB;
                exp.fac <- nfacA;
            }
            # update with new index
            ord.inx <- order(exp.fac);
            dataSet$time.fac <<- time.fac[ord.inx];
            dataSet$exp.fac <<- exp.fac[ord.inx];
        }else{
            ord.inx <- order(cls);
        }
        data<-data[ord.inx, ];
        cls <-cls[ord.inx];
        dataSet$facA <<- dataSet$facA[ord.inx];
        dataSet$facB <<- dataSet$facB[ord.inx];
    }else{
        ord.inx <- order(cls);
        data<-data[ord.inx, ];
        cls <-cls[ord.inx];
    }

    colNames <- colnames(data);
    rowNames <- rownames(data);
    
    # row-wise normalization
    if(rowNorm=="QuantileNorm"){
        data<-QuantileNormalize(data);
        # this can introduce constant variables if a variable is 
        # at the same rank across all samples (replaced by its average across all)

        varCol <- apply(data, 2, var, na.rm=T);
        constCol <- (varCol == 0 | is.na(varCol));
        constNum <- sum(constCol, na.rm=T);
        if(constNum > 0){
            print(paste("After quantile normalization", constNum, "columns with constant value were found and deleted."));
            data <- data[,!constCol];
            colNames <- colnames(data);
            rowNames <- rownames(data);
        }
        rownm<-"Quantile Normalization";
    }else if(rowNorm=="ProbNormT"){
        grp.inx <- cls == ref;
        ref.smpl <- apply(data[grp.inx, ], 2, mean);
        data<-t(apply(data, 1, ProbNorm, ref.smpl));
        rownm<-"Probabilistic Quotient Normalization";
    }else if(rowNorm=="ProbNormF"){
        ref.smpl <- data[ref,];
        data<-t(apply(data, 1, ProbNorm, ref.smpl));
        rownm<-"Probabilistic Quotient Normalization";
    }else if(rowNorm=="CompNorm"){
        data<-t(apply(data, 1, CompNorm, ref));
        rownm<-"Normalization by a reference feature";
    }else if(rowNorm=="SumNorm"){
        data<-t(apply(data, 1, SumNorm));
        rownm<-"Normalization to constant sum";
    }else if(rowNorm=="MedianNorm"){
        data<-t(apply(data, 1, MedianNorm));
        rownm<-"Normalization to sample median";
    }else if(rowNorm=="SpecNorm"){
        if(!exists("norm.vec")){
            norm.vec <- rep(1,nrow(data)); # default all same weight vec to prevent error
            print("No sample specific information were given, all set to 1.0");
         }
         rownm<-"Normalization by sample-specific factor";
         data<-data/norm.vec;
    }else{
        # nothing to do
        rownm<-"N/A";
    }

   # use apply will lose dimesion info (i.e. row names and colnames)
   rownames(data)<-rowNames;
   colnames(data)<-colNames;

   # note: row-normed data is based on biological knowledge, since the previous
   # replacing zero/missing values by half of the min positive (a constant) 
   # now may become different due to different norm factor, which is artificial
   # variance and should be corrected again
   #
   # stopped, this step cause troubles
   # minConc<-round(min(data)/2, 5);
   # data[dataSet$fill.inx]<-minConc;

   # if the reference by feature, the feature column should be removed, since it is all 1
    if(rowNorm=="CompNorm" && !is.null(ref)){
        inx<-match(ref, colnames(data));
        data<-data[,-inx];
        colNames <- colNames[-inx];
    }

   # record row-normed data for fold change analysis (b/c not applicable for mean-centered data)
   dataSet$row.norm<<-as.data.frame(CleanData(data));

   # this is for biomarker analysis only (for compound concentraion data)
    if(ratio){
        min.val <- min(abs(data[data!=0]))/2;
        norm.data <- log2((data + sqrt(data^2 + min.val))/2);
        transnm<-"Log Normalization";
        ratio.mat <- CalculatePairwiseDiff(norm.data);

        fstats <- Get.Fstat(ratio.mat, cls);
        hit.inx <- rank(-fstats) < ratioNum;  # get top n
        ratio.mat <- ratio.mat[, hit.inx];

        data <- cbind(norm.data, ratio.mat);
        colNames <- colnames(data);
        rowNames <- rownames(data);
    }

    if(!ratio){
        # transformation
        if(transNorm=='LogNorm'){
            min.val <- min(abs(data[data!=0]))/10;
            data<-apply(data, 2, LogNorm, min.val);
            transnm<-"Log Normalization";
        }else if(transNorm=='CrNorm'){
            norm.data <- abs(data)^(1/3);
            norm.data[data<0] <- - norm.data[data<0];
            data <- norm.data;
            transnm<-"Cubic Root Transformation";
        }else{
            transnm<-"N/A";
        }
    }

    # scaling
    if(scaleNorm=='MeanCenter'){
            data<-apply(data, 2, MeanCenter);
            scalenm<-"MeanCenter";
    }else if(scaleNorm=='AutoNorm'){
            data<-apply(data, 2, AutoNorm);
            scalenm<-"Autoscaling";
    }else if(scaleNorm=='ParetoNorm'){
            data<-apply(data, 2, ParetoNorm);
            scalenm<-"Pareto Scaling";
    }else if(scaleNorm=='RangeNorm'){
            data<-apply(data, 2, RangeNorm);
            scalenm<-"Range Scaling";
    }else{
            scalenm<-"N/A";
    }

    # need to do some sanity check, for log there may be Inf values introduced
    data <- CleanData(data, T, F);

    # note after using "apply" function, all the attribute lost, need to add back
    rownames(data)<-rowNames;
    colnames(data)<-colNames;

    dataSet$norm <<- as.data.frame(data);
    dataSet$cls <<- cls;

    dataSet$rownorm.method<<-rownm;
    dataSet$trans.method<<-transnm;
    dataSet$scale.method<<-scalenm;
    dataSet$combined.method<<-FALSE;
    dataSet$norm.all <<- NULL; # this is only for biomarker ROC analysis
    return(1);
}

########################################
###row-wise norm methods, x is a row ###
########################################

# normalize by a sum of each sample, assume constant sum (1000)
# return: normalized data
SumNorm<-function(x){
    1000*x/sum(x, na.rm=T);
}

# normalize by median
MedianNorm<-function(x){
    x/median(x, na.rm=T);
}

# normalize by a reference sample (probability quotient normalization)
# ref should be the name of the reference sample
ProbNorm<-function(x, ref.smpl){
    x/median(as.numeric(x/ref.smpl), na.rm=T)
}

# normalize by a reference reference (i.e. creatinine)
# ref should be the name of the cmpd
CompNorm<-function(x, ref){
	1000*x/x[ref];
}

# perform quantile normalization on the raw data (can be log transformed later by user)
# https://stat.ethz.ch/pipermail/bioconductor/2005-April/008348.html
QuantileNormalize <- function(data){
    library('preprocessCore');
    return(t(normalize.quantiles(t(data), copy=FALSE)));
}

##############################################
###column-wise norm methods, x is a column ###
##############################################

# generalize log, tolerant to 0 and negative values
LogNorm<-function(x,min.val){
	 log2((x + sqrt(x^2 + min.val^2))/2)
}

# normalize to zero mean and unit variance
AutoNorm<-function(x){
	(x - mean(x))/sd(x, na.rm=T);
}

# normalize to zero mean but varaince/SE
ParetoNorm<-function(x){
	(x - mean(x))/sqrt(sd(x, na.rm=T));
}

# normalize to zero mean but varaince/SE
MeanCenter<-function(x){
	x - mean(x);
}

# normalize to zero mean but varaince/SE
RangeNorm<-function(x){
    if(max(x) == min(x)){
        x;
    }else{
        (x - mean(x))/(max(x)-min(x));
    }
}


##############################################
################## Summary plot ##############
##############################################

# plot two summary plot, one b4 normalization, one after
# for each plot top is box plot, bottom is a density plot
PlotNormSummary<-function(imgName, format="png", dpi=72, width=NA){

    imgName = paste(imgName, "dpi", dpi, ".", format, sep="");
    if(is.na(width)){
        w <- 10.5; h <- 12;
    }else if(width == 0){
        w <- 7.2;h <- 9;
        imgSet$norm<<-imgName;
    }else{
        w <- 7.2; h <- 9;
    }

    Cairo(file = imgName, unit="in", dpi=dpi, width=w, height=h, type=format, bg="white");
    layout(matrix(c(1,2,2,2,3,4,4,4), 4, 2, byrow = FALSE))

    # since there may be too many compounds, only plot a subsets (50) in box plot
    # but density plot will use all the data

    pre.inx<-GetRandomSubsetIndex(ncol(dataSet$proc), sub.num=50);
    namesVec <- colnames(dataSet$proc[,pre.inx]);

    # only get common ones
    nm.inx <- namesVec %in% colnames(dataSet$norm)
    namesVec <- namesVec[nm.inx];
    pre.inx <- pre.inx[nm.inx];

    norm.inx<-match(namesVec, colnames(dataSet$norm));
    namesVec <- substr(namesVec, 1, 12); # use abbreviated name

    rangex.pre <- range(dataSet$proc[, pre.inx], na.rm=T);
    rangex.norm <- range(dataSet$norm[, norm.inx], na.rm=T);

    x.label<-GetValueLabel();
    y.label<-GetVariableLabel();

    # fig 1
    op<-par(mar=c(4,7,4,0), xaxt="s");
    plot(density(apply(dataSet$proc, 2, mean, na.rm=TRUE)), col='darkblue', las =2, lwd=2, main="", xlab="", ylab="");
    mtext("Density", 2, 5);
    mtext("Before Normalization",3, 1)

    # fig 2
    op<-par(mar=c(7,7,0,0), xaxt="s");
    boxplot(dataSet$proc[,pre.inx], names= namesVec, ylim=rangex.pre, las = 2, col="lightgreen", horizontal=T);
    mtext(x.label, 1, 5);

    # fig 3
    op<-par(mar=c(4,7,4,2), xaxt="s");
    plot(density(apply(dataSet$norm, 2, mean, na.rm=TRUE)), col='darkblue', las=2, lwd =2, main="", xlab="", ylab="");
    mtext("After Normalization",3, 1);

    # fig 4
    op<-par(mar=c(7,7,0,2), xaxt="s");
    boxplot(dataSet$norm[,norm.inx], names=namesVec, ylim=rangex.norm, las = 2, col="lightgreen", horizontal=T);
    mtext(paste("Normalized",x.label),1, 5);

    dev.off();
}

PlotSampleNormSummary<-function(imgName, format="png", dpi=72, width=NA){
    imgName = paste(imgName, "dpi", dpi, ".", format, sep="");
    if(is.na(width)){
        w <- 10.5; h <- 12;
    }else if(width == 0){
        w <- 7.2;h <- 9;
        imgSet$norm<<-imgName;
    }else{
        w <- 7.2; h <- 9;
    }

    Cairo(file = imgName, unit="in", dpi=dpi, width=w, height=h, type=format, bg="white");
    layout(matrix(c(1,1,1,2,3,3,3,4), 4, 2, byrow = FALSE))

    # since there may be too many samples, only plot a subsets (50) in box plot
    # but density plot will use all the data

    pre.inx<-GetRandomSubsetIndex(nrow(dataSet$proc), sub.num=50);
    namesVec <- rownames(dataSet$proc[pre.inx,]);

    # only get common ones
    nm.inx <- namesVec %in% rownames(dataSet$norm)
    namesVec <- namesVec[nm.inx];
    pre.inx <- pre.inx[nm.inx];

    norm.inx<-match(namesVec, rownames(dataSet$norm));
    namesVec <- substr(namesVec, 1, 12); # use abbreviated name

    rangex.pre <- range(dataSet$proc[pre.inx,], na.rm=T);
    rangex.norm <- range(dataSet$norm[norm.inx,], na.rm=T);

    x.label<-GetValueLabel();
    y.label<-"Samples";

    # fig 1
    op<-par(mar=c(5,7,4,0), xaxt="s");
    boxplot(t(dataSet$proc[pre.inx, ]), names= namesVec, ylim=rangex.pre, las = 2, col="lightgreen", horizontal=T);
    mtext("Before Normalization",3, 1);

    # fig 2
    op<-par(mar=c(7,7,0,0), xaxt="s");
    plot(density(apply(dataSet$proc, 1, mean, na.rm=TRUE)), col='darkblue', las =2, lwd=2, main="", xlab="", ylab="");
    mtext("Density", 2, 5);
    mtext(x.label, 1, 5);

    # fig 3
    op<-par(mar=c(5,7,4,2), xaxt="s");
    boxplot(t(dataSet$norm[norm.inx,]), names=namesVec, ylim=rangex.norm, las = 2, col="lightgreen", horizontal=T);
    mtext("After Normalization",3, 1);

    # fig 4
    op<-par(mar=c(7,7,0,2), xaxt="s");
    plot(density(apply(dataSet$norm, 1, mean, na.rm=TRUE)), col='darkblue', las=2, lwd =2, main="", xlab="", ylab="");
    mtext(paste("Normalized",x.label),1, 5);

    dev.off();
}